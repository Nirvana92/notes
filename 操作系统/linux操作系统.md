#### 操作系统

> 安装在硬件基础之上, 通过响应用户输入的指令达到控制硬件的效果, 从而满足用户需求。这层软件为操作系统。

**参考博文:** `https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzU2NDg0OTgyMA==&action=getalbum&album_id=1323237725822337024&subscene=159&subscene=&scenenote=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FaAh3gYS_SNxl7VDNbb6H2Q#wechat_redirect`

大部分计算机有两种运行模式: `内核态`和`用户态`;操作系统运行在`内核态`, 内核态也叫`管态`和`核心态`.他们都是操作系统的运行状态。操作系统具有硬件的访问权。软件的其余部分运行在`用户态`。

![img](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdWiaexJhvU13C7OJUrpibcRL58hXWAFwgrdk2NcFkz4dAdrRYwByNfMLriaUib5DibaH8mZE4mQ23dzx6A/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

电脑抽象模型: CPU, 内存, IO设备和总线。

##### CPU





##### 线程上下文切换

如果没有进程处于就绪状态, 系统提供的**空闲进程**通常会运行。

调度算法: 

**非抢占式: **挑选一个进程，让该进程运行直到被阻塞[阻塞在io或等待另一个进程]，或直到该进程自动释放CPU。即使该进程运行了若干个小时后，它也不会被强制挂起。

**抢占式:** 它会选择一个进程，并使其在最大固定时间内运行。如果在时间间隔结束后仍在运行。这个进程会被挂起。调度程序会选择其他进程来运行[前提是存在就绪进程]。

调度算法优化分环境而定: 

1. 批处理: 处理工资单、存货清单。一般选择使用非抢占式算法或周期比较长的抢占式算法。可以减少线程切换因此能够提升性能。
2. 交互式: 避免一个进程霸占CPU拒绝为其他进程服务，所以需要抢占式算法。
3. 实时: 实时系统和交互式系统的差别, 实时系统只运行那些用来推进现有应用的程序，而交互式系统是通用的。它可以运行任意的非协作甚至是有恶意的程序。

#### 批处理中的调度

特定的调度算法: 

**先来先服务:** 第一个任务从外部进入系统时, 将会立即启动并允许运行任意长的时间。它不会因为运行时间太长而中断。当其他作业进入时，它们排到就绪队列尾部。当正在运行的进程阻塞，处于等待队列的第一个进程就开始运行。当一个阻塞的进程重新处于就绪状态时，它就会像一个新到达的任务，会排在队列的末尾，即排在所有进程最后。

优点: 易于理解和编程, 一个单链表记录了所有就绪进程。

缺点: 没有优先级的关系。

**最短作业优先:** 假设运行时间已知。按照最短时间作为优先级进行排序。

> 需要注意的是, 在所有的进程都可以运行的情况下。最短作业优先的算法才是最优的。

**最短剩余时间优先:** 调度程序总是选择剩余运行时间最短的进程运行。当一个新作业到达时，其整个时间同当前的剩余时间做比较。如果新的进程比当前进程需要更少的时间，当前进程就被挂起。而运行新的进程。这种方式能够使短期作业获得良好的服务。

#### 交互式系统中的调度

**轮询调度:** 每个进程都会被分配一个时间段, 称为**时间片**,在这个时间片内允许进程运行。如果时间片结束时进程还在运行的话，则抢占一个CPU并将其分配给另一个进程。如果进程在时间片结束前阻塞或结束，则CPU立即进行切换。

> 从一个进程切换到另一个进程需要一定的时间进行管理处理，包括保存寄存器的值和内存映射、更新不同的表格和列表、清除和重新调入内存高速缓存等。这种切换称作**进程间切换**和**上下文切换**。

**优先级调度:** 轮询假设了所有的进程是同等重要的。但事实情况可能不是这样的。每个进程都被赋予一个优先级。优先级高的优先运行。

但是优先级高的进程也不是能够永远一直运行下去，调度程序会在每个时钟中断期间降低当前运行进程的优先级。如果此操作导致优先级降低到下一个最高进程的优先级一下。则会发生进程切换。或者可以为每个进程分配运行运行的最大时间间隔。当时间间隔用完了，下一个高优先级的进程会得到运行的机会。

#### 线程调度

需要考虑是用户级别的线程还是内核级别的线程[还是两者都支持]。

用户级别的线程: 根据内核分配给进程的时间片来限制。

内核级别的线程: 内核选择一个特定的线程运行。不用考虑线程属于哪个进程。

> 用户级线程和内核级线程之间的主要差别在于`性能`。用户级线程的切换需要少量的机器指令（想象一下Java程序的线程切换），而内核线程需要完整的上下文切换，修改内存映像，使高速缓存失效，这会导致了若干数量级的延迟。另一方面，在使用内核级线程时，一旦线程阻塞在 I/O 上就不需要在用户级线程中那样将整个进程挂起。
>
> 从进程 A 的一个线程切换到进程 B 的一个线程，其消耗要远高于运行进程 A 的两个线程（涉及修改内存映像，修改高速缓存），内核对这种切换的消耗是了解到，可以通过这些信息作出决定。

#### 内存

主存[ram], 分层存储器体系。

寄存器: 访问时间: 1ns, 大小: <1kb

高速缓存: 访问时间: 2ns, 大小: 4mb

主存: 访问时间: 10ns, 大小: 1~8gb

磁盘: 访问时间: 10ms, 大小: 1~4tb

**RAM:** 随机存取存储器[Random Access Memory].也叫主存。是与CPU直接交换数据的内存存储器。它可以随时读写[刷新时除外].速度很快。通常作为操作系统与其他正在运行中的程序的临时数据存储介质。RAM工作时可以随时从任何一个指定的地址写入[存入]或读出[取出]信息。它与ROM的最大区别是数据的易失性。

**ROM:** 只读存储器[Read-Only Memory, ROM]非破坏性读出方式工作。只能读出无法写入信息。信息一旦写入后就固定下来。切断电源信息也不会丢失。又称固定存储器。bios 存储地方。

**PSW:** 程序状态字[程序状态寄存器, Program Status Word]。

**地址空间[the address space]:** 创建了一种抽象内存供程序使用。地址空间是进程可以用来寻址内存的地址集。每个进程都有它自己的地址空间，独立于其他进程的地址空间。但是某些进程会希望可以共享地址空间。

**动态重定位[dynamic relocation]:** 通过一种简单的方式将每个进程的地址空间映射到物理内存的不同区域。方法: 给每个CPU配置两个特殊硬件寄存器.**基址寄存器[basic register]**和**变址寄存器[limit register]**。当一个进程运行时, 程序的起始物理地址装在到基址寄存器中, 程序的长度则装在到变址寄存器中。

**基址寄存器:** 存储数据内存的起始位置。

**变址寄存器:** 存储应用程序的长度。

**内存总线:** ?



处理的问题: 系统中运行程序所需要的内存远比提供的内存大得多。所以需要处理这种内存不足的情况。

方式: 

**交换技术:** 一个进程完整的调入内存, 然后在内存中运行一段时间, 再把它放回磁盘。空闲进程会存储在磁盘中。

![img](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdVbdVAnWs4le1cXSNiaXJoXy1ib57I9E4DG0PKicUch3fmMXpgaYb9wUhhUkWx8HBH457Oe5nQtxtwHw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

缺点: 容易产生比较多的外碎片[进程间的碎片]。分页之后有可能导致产生内碎片。每页4k, 相对来说内碎片足够小。

上面这种产生内存碎片可以通过**内存紧缩**[内存会把所有空闲区尽可能向下移动合并成为一个大的空闲区]。解决部分问题。通常这种技术不会使用, 因为这项技术会消费很多CPU时间。

**代码段[codesegment]:** 又称文本段, 用来存放指令, 运行代码的一块内存空间。一般只读, 某些架构的代码也允许可写。

**数据段[datasegment]:** 可读可写.存储初始化的变量和初始化的static变量。数据段中数据的生存期是随恒旭持续性[随进程持续性]。进程存在就存在, 进程死亡就消失。

**bss段[bsssegment]:** 可读可写, 存储未初始化的全局变量和未初始化的static变量。

bss段中的数据一般默认为0。

**rodata段:** 只读数据。常量区。比如全局作用域 const int val = 10; val 存放在 .rodata段。再比如: printf("hello %d \n", c); 语句中的格式字符串 "hello %d \n"也是存放在 .rodata段。

**栈[stack]:** 可读可写; 存储的是函数或代码中的局部变量[非static变量]。栈的生存期随代码块持续性。代码运行就分配空间。代码结束就回收空间、

**堆[heap]:** 可读可写; 存储的是程序运行期间动态分配的(malloc/realloc)的空间。堆的生存期随进程持续, 从(malloc/realloc)到free一直存在。

**虚拟内存:** 允许应用程序部分的运行在磁盘中。

##### 空闲内存管理

动态分配内存的时候, 操作系统管理内存的方式: 

1. 位图[bitmap]
2. 空闲列表[free lists]

**位图:** 

位图方法时, 内存可能被划分为小到几个字大到几千字节的分配单元。每个分配单元对应于位图中的一位。

![img](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdVbdVAnWs4le1cXSNiaXJoXy3PEMF7WhTaRffICfzlS6ZAKJ2NapHzuHBePgUo00n0OEfhIkWTPOwA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

优点: 通过少量的位图空间减少碎片的空间浪费。

缺点: 当需要找到指定长度的连续空闲区间是一个很耗时的操作。

**空闲列表:** 维护一个记录已分配内存段和空闲内存段的链表, 段会包含进程或者是两个进程的空闲区域。

首次适配: 内存管理器会沿着序列表进行扫描, 直到找到下一个足够大的空闲区为止。[速度快]

下次适配: 和首次适配工作方式相同. 不同之处下次适配在每次找到合适的空闲区就会记录当时的位置。以便下次寻找空闲区从上次结束的地方开始搜索。

最佳适配: 从头到尾寻找整个链表。找出能够容纳进程的最小空闲区。最佳适配算法试图找出最接近实际需要的空闲区，以最好的匹配请求和可用空闲区。

##### 互斥方案

**屏蔽中断:** 单处理器系统上, 让每个进程在进入临界区后立即`屏蔽所有中断`, 并在离开临界区之前重新启用他们。

**锁变量:** 软件层面的解决方案; 考虑有单个共享的[锁]变量。初始值为0.当一个线程想要进入关键区域时，它会首先查看锁的值是否为0.如果是设置为1.

**严格轮询法:** 通过共享变量的指定值来特殊控制;

```java
// 进程0
while(TRUE){
  while(turn != 0){
    /* 进入关键区域 */
    critical_region();
    turn = 1;
    /* 离开关键区域 */
    noncritical_region();
  }
}
```

```java
// 进程1
while(TRUE){
  while(turn != 1){
    critical_region();
    turn = 0;
    noncritical_region();
  }
}
```

**Peterson解法:** 荷兰数学家 Dekker 通过将锁变量与警告变量相结合，最早提出了一个不需要严格轮换的软件互斥算法。

后来Peterson发现了一种简单很多的互斥算法, 如下: 

```c
#define FALSE 0
#define TRUE  1
/* 进程数量 */
#define N     2                                                    

/* 现在轮到谁 */
int turn;                    

/* 所有值初始化为 0 (FALSE) */
int interested[N];                                            

/* 进程是 0 或 1 */
void enter_region(int process){                    

  /* 另一个进程号 */
  int other;                                                        

  /* 另一个进程 */
  other = 1 - process;                

  /* 表示愿意进入临界区 */
  interested[process] = TRUE;                        
  turn = process;

  /* 空循环 */
  while(turn == process 
        && interested[other] == true){} 

}

void leave_region(int process){

  /* 表示离开临界区 */
  interested[process] == FALSE;                 
}
```

**TSL指令:** 硬件帮助的方案; 通过指令`TSL RX, LOCK`; `xchg`本质上与`TSL`的解决办法一样。

##### 睡眠与唤醒

上面的方法Peterson/TSL/XCHG 都是正确的。但是他们都有忙等待的缺点[原地等待]。

可能出现的问题: `优先级反转问题`

睡眠与唤醒进程间的通信原语: `sleep`和`wakeup`

**信号量：** 一个整形变量来累积唤醒次数。

**互斥量:**  信号量的一个简单版本, 称为`mutex[互斥量]`。互斥量的优势在于一些共享资源和一段代码中保持互斥。

**Futexes:** 随着并行的增加, 有效的同步和锁定对于性能来说非常重要。如果进程等待时间很短。那么`自旋锁[spin lock]`是非常有效的。如果时间比较长, 那么会浪费CPU周期。

另一种解决办法是把两者的有点结合起来 提出一种新的思想。称为`Futex`, 或`快速用户空间互斥`;

`Futex`是Linux中的特性实现了基本的锁定, 而且避免了陷入内核中。因为内核的切换的开销非常大，这样可以大大提高性能。

**管程:** 为了能够编写更加准确无误的程序, Brinch Hansen 和Hoars 提出了一个更高级的同步原语: `管程[monitor]`。管程是程序、变量和数据结构等组成的一个集合，它们组成一个特殊的模块或者包。进程可以在任何需要的时候调用管程中的程序，但是它们不能从管程外部访问数据结构和程序。

进入管程中的互斥由编译器负责，但是一种通用做法是使用 `互斥量(mutex)` 和 `二进制信号量(binary semaphore)`。由于编译器而不是程序员在操作，因此出错的几率会大大降低。在任何时候，编写管程的程序员都无需关心编译器是如何处理的。他只需要知道将所有的临界区转换成为管程过程即可。绝不会有两个进程同时执行临界区中的代码。

即使管程提供了一种简单的方式来实现互斥，但在我们看来，这还不够。因为我们还需要一种在进程无法执行被阻塞。在生产者-消费者问题中，很容易将针对缓冲区满和缓冲区空的测试放在管程程序中，但是生产者在发现缓冲区满的时候该如何阻塞呢？

解决的办法是引入`条件变量(condition variables)` 以及相关的两个操作 `wait` 和 `signal`。当一个管程程序发现它不能运行时（例如，生产者发现缓冲区已满），它会在某个条件变量（如 full）上执行 `wait` 操作。这个操作造成调用进程阻塞，并且还将另一个以前等在管程之外的进程调入管程。在前面的 pthread 中我们已经探讨过条件变量的实现细节了。另一个进程，比如消费者可以通过执行 `signal` 来唤醒阻塞的调用进程。

读者可能觉得 wait 和 signal 操作看起来像是前面提到的 sleep 和 wakeup ，而且后者存在严重的竞争条件。它们确实很像，但是有个关键的区别：sleep 和 wakeup 之所以会失败是因为当一个进程想睡眠时，另一个进程试图去唤醒它。使用管程则不会发生这种情况。管程程序的自动互斥保证了这一点，如果管程过程中的生产者发现缓冲区已满，它将能够完成 wait 操作而不用担心调度程序可能会在 wait 完成之前切换到消费者。甚至，在 wait 执行完成并且把生产者标志为不可运行之前，是不会允许消费者进入管程的。

##### 消息传递

上面提到的其他方法就是 `消息传递(messaage passing)`。这种进程间通信的方法使用两个原语 `send` 和 `receive` ，它们像信号量而不像管程，是系统调用而不是语言级别。

##### 屏障

最后一个同步机制是准备用于进程组而不是进程间的生产者-消费者情况的。在某些应用中划分了若干阶段，并且规定，除非所有的进程都就绪准备着手下一个阶段，否则任何进程都不能进入下一个阶段，可以通过在每个阶段的结尾安装一个 `屏障(barrier)` 来实现这种行为。当一个进程到达屏障时，它会被屏障所拦截，直到所有的屏障都到达为止。屏障可用于一组进程同步，如下图所示

![img](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXktobEIdqeRzlib8Q2NE2hBvwcInsibDwCw80fyuPwWZ9GBugIdpLYMbeA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

在上图中我们可以看到，有四个进程接近屏障，这意味着每个进程都在进行运算，但是还没有到达每个阶段的结尾。过了一段时间后，A、B、D 三个进程都到达了屏障，各自的进程被挂起，但此时还不能进入下一个阶段呢，因为进程 B 还没有执行完毕。结果，当最后一个 C 到达屏障后，这个进程组才能够进入下一个阶段。

##### 避免锁：读-复制-更新

最快的锁是根本没有锁。问题在于没有锁的情况下，我们是否允许对共享数据结构的并发读写进行访问。答案当然是不可以。假设进程 A 正在对一个数字数组进行排序，而进程 B 正在计算其平均值，而此时你进行 A 的移动，会导致 B 会多次读到重复值，而某些值根本没有遇到过。

##### 虚拟内存

尽管基址寄存器和变址寄存器用来创建地址空间的抽象，但是这有一个其他的问题需要解决：`管理软件的膨胀(managing bloatware)`。而交换技术并不是一个很有效的方案，在一些中小应用程序尚可使用交换，如果应用程序过大，难道还要每次交换几 GB 的内存？一个典型的 `SATA` 磁盘的峰值传输速度高达几百兆/秒，这意味着需要好几秒才能换出或者换入一个 1 GB 的程序。

> SATA（Serial ATA）硬盘，又称串口硬盘，是未来 PC 机硬盘的趋势，已基本取代了传统的 PATA 硬盘。

那么还有没有一种有效的方式来应对呢？有，那就是使用 `虚拟内存(virtual memory)`，虚拟内存的基本思想是，每个程序都有自己的地址空间，这个地址空间被划分为多个称为`页面(page)`的块。每一页都是连续的地址范围。这些页被映射到物理内存，但并不是所有的页都必须在内存中才能运行程序。当程序引用到一部分在物理内存中的地址空间时，硬件会立刻执行必要的映射。当程序引用到一部分不在物理内存中的地址空间时，由操作系统负责将缺失的部分装入物理内存并重新执行失败的指令。

##### 虚拟内存实现

虚拟内存很适合在多道程序设计系统中使用，许多程序的片段同时保存在内存中，当一个程序等待它的一部分读入内存时，可以把 CPU 交给另一个进程使用。

##### 分页

大部分使用虚拟内存的系统中都会使用一种 `分页(paging)` 技术。在任何一台计算机上，程序会引用使用一组内存地址。当程序执行

```shell
MOV REG,1000
```

这条指令时，它会把内存地址为 1000 的内存单元的内容复制到 REG 中（或者相反，这取决于计算机）。地址可以通过索引、基址寄存器、段寄存器或其他方式产生。

这些程序生成的地址被称为 `虚拟地址(virtual addresses)` 并形成`虚拟地址空间(virtual address space)`，在没有虚拟内存的计算机上，系统直接将虚拟地址送到内存中线上，读写操作都使用同样地址的物理内存。**在使用虚拟内存时，虚拟地址不会直接发送到内存总线上**。相反，会使用 `MMU(Memory Management Unit)` 内存管理单元把**虚拟地址映射为物理内存地址**，像下图这样

![img](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUUA7J9aewOcy25TbfOjaMhEZLkIC8Mekicn0ceW8JWd4VCYQ9gTFDdFP6rgOPL1L39nOPyyE3Lf2w/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

下面这幅图展示了这种映射是如何工作的

![img](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUUA7J9aewOcy25TbfOjaMhSkeVptZ4dgAoTYzcg4nngdc8mxPWU9t6f2jIoNqeuHGYibzQcsqSRLw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

页表给出虚拟地址与物理内存地址之间的映射关系。每一页起始于 4096 的倍数位置，结束于 4095 的位置，所以 4K 到 8K 实际为 4096 - 8191 ，8K - 12K 就是 8192 - 12287

**存在映射的页如何映射:** 

虚拟地址空间由固定大小的单元组成，这种固定大小的单元称为 `页(pages)`。而相对的，物理内存中也有固定大小的物理单元，称为 `页框(page frames)`。页和页框的大小一样。在上面这个例子中，页的大小为 4KB ，但是实际的使用过程中页的大小范围可能是 512 字节 - 1G 字节的大小。对应于 64 KB 的虚拟地址空间和 32 KB 的物理内存，可得到 16 个虚拟页面和 8 个页框。RAM 和磁盘之间的交换总是以整个页为单元进行交换的。

程序试图访问地址时，例如执行下面这条指令

```shell
MOV REG, 0
```

会将虚拟地址 0 送到 MMU。MMU 看到虚拟地址落在页面 0 （0 - 4095），根据其映射结果，这一页面对应的页框 2 （8192 - 12287），因此 MMU 把地址变换为 8192 ，并把地址 8192 送到总线上。内存对 MMU 一无所知，它只看到一个对 8192 地址的读写请求并执行它。MMU 从而有效的把所有虚拟地址 0 - 4095 映射到了 8192 - 12287 的物理地址。同样的，指令

```shell
MOV REG, 8192
```

也被有效的转换为

```shell
MOV REG, 24576
```

虚拟地址 8192（在虚拟页 2 中）被映射到物理地址 24576（在物理页框 6 中）上。

通过恰当的设置 MMU，可以把 16 个虚拟页面映射到 8 个页框中的任何一个。但是这并没有解决虚拟地址空间比物理内存大的问题。

上图中有 8 个物理页框，于是只有 8 个虚拟页被映射到了物理内存中，在上图中用 `X` 号表示的其他页面没有被映射。在实际的硬件中，会使用一个 `在/不在(Present/absent bit)`位记录页面在内存中的实际存在情况。

**未映射的页如何映射**

当程序访问一个未映射的页面，如执行指令

```shell
MOV REG, 32780
```

将会发生什么情况呢？虚拟页面 8 （从 32768 开始）的第 12 个字节所对应的物理地址是什么？MMU 注意到该页面没有被映射（在图中用 X 号表示），于是 CPU 会`陷入(trap)`到操作系统中。这个陷入称为 `缺页中断(page fault)` 或者是 `缺页错误`。操作系统会选择一个很少使用的页并把它的内容写入磁盘（如果它不在磁盘上）。随后把需要访问的页面读到刚才回收的页框中，修改映射关系，然后重新启动引起陷入的指令。有点不太好理解，举个例子来看一下。

例如，如果操作系统决定放弃页框 1，那么它将把虚拟机页面 8 装入物理地址 4096，并对 MMU 映射做两处修改。首先，它要将虚拟页中的 1 表项标记为未映射，使以后任何对虚拟地址 4096 - 8191 的访问都将导致陷入。随后把虚拟页面 8 的表项的叉号改为 1，因此在引起陷阱的指令重新启动时，它将把虚拟地址 32780 映射为物理地址（4096 + 12）。

**页表**

在上面这个简单的例子中，虚拟地址到物理地址的映射可以总结如下：虚拟地址被分为`虚拟页号（高位部分）`和`偏移量（低位部分）`。例如，对于 16 位地址和 4 KB 的页面大小，高 4 位可以指定 16 个虚拟页面中的一页，而低 12 位接着确定了所选页面中的偏移量（0-4095）。

虚拟页号可作为页表的索引用来找到虚拟页中的内容。由页表项可以找到页框号（如果有的话）。然后把页框号拼接到偏移量的高位端，以替换掉虚拟页号，形成物理地址。





#### 主存[RAM]



